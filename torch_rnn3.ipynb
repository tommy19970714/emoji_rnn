{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable #è‡ªå‹•å¾®åˆ†ç”¨\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_nums: [(8, 2206), (6, 1364), (18, 1022), (4, 894), (17, 807), (10, 649), (19, 512), (13, 489), (11, 476), (3, 444), (1, 397), (12, 372), (2, 305), (5, 228), (15, 203), (14, 186), (9, 172), (20, 167), (16, 162), (7, 128)]\n",
      "min_num: 128\n",
      "ã‚¯ãƒ©ã‚¹8 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 2078 (94.20ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹6 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 1236 (90.62ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹18 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 894 (87.48ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹4 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 766 (85.68ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹17 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 679 (84.14ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹10 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 521 (80.28ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹19 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 384 (75.00ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹13 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 361 (73.82ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹11 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 348 (73.11ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹3 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 316 (71.17ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹1 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 269 (67.76ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹12 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 244 (65.59ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹2 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 177 (58.03ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹5 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 100 (43.86ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹15 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 75 (36.95ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹14 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 58 (31.18ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹9 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 44 (25.58ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹20 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 39 (23.35ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹16 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 34 (20.99ï¼…)\n",
      "ã‚¯ãƒ©ã‚¹7 å‰Šé™¤ã‚µãƒ³ãƒ—ãƒ«æ•°: 0 (0.00ï¼…)\n"
     ]
    }
   ],
   "source": [
    "dataloader = util.dataloader()\n",
    "dataloader.normalize()\n",
    "X_train, X_test, y_train, y_test = dataloader.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ğŸ˜…']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "emoji_index = pickle.loads(open('./emoji_index.pkl', 'rb').read())\n",
    "def emojiFromIndex(num):\n",
    "    return [k for k, v in emoji_index.items() if v == num]\n",
    "\n",
    "emojiFromIndex(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('text_label_split_big.tsv', encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 1054723 sentence pairs\n",
      "Trimmed to 1054723 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "in 94101\n",
      "out 22\n",
      "['æ¡ä»¶ ã¯ ç‰¹ã« ã‚ã‚Šã¾ã›ã‚“ ãŒ ã€ æ¯æ—¥ ãƒ­ã‚°ã‚¤ãƒ³ ã€ åŒè¡Œ å› ç¨‹åº¦ ã— ã¦ ã‚‚ã‚‰ãˆã‚‹ ã¨ æ³£ã„ ã¦ å–œã³ ã¾ã™ ', '3']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('in', 'out', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        print('original emoji = ', emojiFromIndex(int(pair[1])))\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('output emoji < ', emojiFromIndex(int(output_words[0])))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 40s (- 23m 24s) (5000 6%) 1.3855\n",
      "3m 17s (- 21m 21s) (10000 13%) 1.2578\n",
      "4m 54s (- 19m 39s) (15000 20%) 1.1855\n",
      "6m 32s (- 17m 58s) (20000 26%) 1.1133\n",
      "8m 9s (- 16m 18s) (25000 33%) 1.1037\n",
      "9m 47s (- 14m 40s) (30000 40%) 1.0823\n",
      "11m 25s (- 13m 2s) (35000 46%) 1.0477\n",
      "13m 1s (- 11m 24s) (40000 53%) 1.0489\n",
      "14m 39s (- 9m 46s) (45000 60%) 1.0168\n",
      "16m 16s (- 8m 8s) (50000 66%) 1.0032\n",
      "17m 54s (- 6m 30s) (55000 73%) 0.9789\n",
      "19m 32s (- 4m 53s) (60000 80%) 0.9775\n",
      "21m 8s (- 3m 15s) (65000 86%) 0.9586\n",
      "22m 46s (- 1m 37s) (70000 93%) 0.9352\n",
      "24m 24s (- 0m 0s) (75000 100%) 0.9483\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ã€Œ å ã‚µã‚¤ãƒ³ å…¥ã‚Š ã‚¹ãƒšã‚·ãƒ£ãƒ« åŠ‡å ´ ãƒã‚¹ã‚¿ãƒ¼ ã€ ã‚’ æŠ½é¸ ã§ ã“ã¡ã‚‰ ã® ãƒ„ã‚¤ãƒ¼ãƒˆ ã‚’ ã— ã¦ ãã ã•ã„ \n",
      "= 19\n",
      "original emoji =  ['ğŸ˜†']\n",
      "< 19 <EOS>\n",
      "output emoji <  ['ğŸ˜†']\n",
      "\n",
      "> ã©ã“ ã« ã©ã® ç´ æ ãŒ ä½¿ã‚ ã‚Œ ã¦ã‚‹ ã‹ è¨˜è¼‰ ãŒ \n",
      "= 19\n",
      "original emoji =  ['ğŸ˜†']\n",
      "< 20 <EOS>\n",
      "output emoji <  ['ğŸ˜³']\n",
      "\n",
      "> ã‚­ãƒ£ã‚¹ãƒˆ ãƒ» ã‚¹ã‚¿ãƒƒãƒ• ã«ã‚ˆã‚‹ èˆå°æŒ¨æ‹¶ ã‚’ äºˆå®š \n",
      "= 6\n",
      "original emoji =  ['ğŸ˜Š']\n",
      "< 6 <EOS>\n",
      "output emoji <  ['ğŸ˜Š']\n",
      "\n",
      "> æœ¬å½“ã« å°é¢¨ ã« ã¯ ååˆ† æ°— ã‚’ ã¤ã‘ ã¾ã—ã‚‡ ã† \n",
      "= 17\n",
      "original emoji =  ['â—']\n",
      "< 8 <EOS>\n",
      "output emoji <  ['âœ¨']\n",
      "\n",
      "> å†™çœŸ ã¯ äº‹å‹™æ‰€ ã® ä¸€è§’ ã‚’ ãƒ‘ã‚·ãƒ£ ã‚Š  ï¸\n",
      "= 17\n",
      "original emoji =  ['â—']\n",
      "< 17 <EOS>\n",
      "output emoji <  ['â—']\n",
      "\n",
      "> å›ãŸã¡ åŒã˜ ã‚ˆã† ãª ã“ã¨ ãƒªãƒ— ã— ã¦ ãã‚‹ ãª  ç¬‘\n",
      "= 3\n",
      "original emoji =  ['ğŸ˜‚']\n",
      "< 3 <EOS>\n",
      "output emoji <  ['ğŸ˜‚']\n",
      "\n",
      "> ã—ã¿ã“ã‚“ ã§ ãã‚‹ ãƒŸãƒ«ã‚¯ ã® ã‚³ã‚¯ ãŒ ãŸã¾ã‚‰ ã‚“ \n",
      "= 8\n",
      "original emoji =  ['âœ¨']\n",
      "< 8 <EOS>\n",
      "output emoji <  ['âœ¨']\n",
      "\n",
      "> ç™ºå£² ã‚¹ã‚¿ãƒ¼ãƒˆ ã‹ã‚‰ å¤§äººæ°— \n",
      "= 8\n",
      "original emoji =  ['âœ¨']\n",
      "< 8 <EOS>\n",
      "output emoji <  ['âœ¨']\n",
      "\n",
      "> æ—¥ä»˜ã‘ å¤‰ã‚ã£ ã¦ ã€ æœ¬æ—¥ æœ æ™‚ ã‹ã‚‰ \n",
      "= 8\n",
      "original emoji =  ['âœ¨']\n",
      "< 8 <EOS>\n",
      "output emoji <  ['âœ¨']\n",
      "\n",
      "> ã‚°ãƒªãƒ¼ãƒ³ãƒã‚¹ é‰¾ç”° â€œ â€ å·è»Š  ï¸\n",
      "= 17\n",
      "original emoji =  ['â—']\n",
      "< 17 <EOS>\n",
      "output emoji <  ['â—']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"ä»²è‰¯ã ã— ã¦\")\n",
    "plt.matshow(attentions.numpy())\n",
    "plt.savefig('frendme.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig('frendme.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    print('output emoji = ', emojiFromIndex(int(output_words[0])))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = å¯Œå£«å‰ç”° èŒ¶èŠ± ã§ã™\n",
      "output = 8 <EOS>\n",
      "output emoji =  ['âœ¨']\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"å¯Œå£«å‰ç”° èŒ¶èŠ± ã§ã™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
