{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable #Ëá™ÂãïÂæÆÂàÜÁî®\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üòÖ']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "emoji_index = pickle.loads(open('./emoji_index.pkl', 'rb').read())\n",
    "def emojiFromIndex(num):\n",
    "    return [k for k, v in emoji_index.items() if v == num]\n",
    "\n",
    "emojiFromIndex(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def readLangs(lang1, lang2, fn, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(fn, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, fn, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, fn, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 530706 sentence pairs\n",
      "Trimmed to 530706 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "in 107663\n",
      "out 22\n",
      "['Êò®Êó• „Éï„Ç©„É≠„ÉØ„Éº „Å´ „Å™„Å£ „Åü Êñπ ÔæÉÔæûÔΩΩ  ', '5']\n",
      "Reading lines...\n",
      "Read 1045 sentence pairs\n",
      "Trimmed to 1045 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "in 2376\n",
      "out 22\n",
      "['„Åì„ÅÆ ÊôÇÊúü „Å´ „Å™„Çã „Å® Â§úÁ©∫ „ÅØ Á∂∫È∫ó „Åß„Åô „Å™„ÅÅ ', '8']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('in', 'out', 'text_label_split.tsv', False)\n",
    "print(random.choice(pairs))\n",
    "\n",
    "input_lang_test, output_lang_test, pairs_test = prepareData('in', 'out', 'text_label_split2.tsv', False)\n",
    "print(random.choice(pairs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses, \"losses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points, filename):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def showConfusionMatrix(y_test, y_pred):\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    index = columns = [str(l) for l in range(len(emoji_index))]\n",
    "    df = pd.DataFrame(conf_mat, index=index, columns=columns)\n",
    "    \n",
    "    fig = plt.figure(figsize = (7,7))\n",
    "    sns.heatmap(df, annot=False, square=True, fmt='.0f', cmap=\"Blues\")\n",
    "    plt.title('20 emojis classification')\n",
    "    plt.xlabel('emojis')\n",
    "    plt.ylabel('prediction')\n",
    "    fig.savefig(\"confusion_matrix_torch3.png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        print('original emoji = ', emojiFromIndex(int(pair[1])))\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('output emoji < ', emojiFromIndex(int(output_words[0])))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def evaluateTestdata(encoder, decoder):\n",
    "    y_test, y_pred = [], []\n",
    "    for pair in pairs_test:\n",
    "        y_test.append(int(pair[1]))\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        y_pred.append(int(output_words[0]))\n",
    "    print(\"precision\", precision_score(y_test, y_pred, average=None))\n",
    "    print(\"report\", classification_report(y_test, y_pred))\n",
    "    print(\"accuracy score\", accuracy_score(y_test, y_pred))\n",
    "    showConfusionMatrix(y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 42s (- 23m 59s) (5000 6%) 1.4156\n",
      "3m 23s (- 22m 5s) (10000 13%) 1.3294\n",
      "5m 5s (- 20m 20s) (15000 20%) 1.2860\n",
      "6m 46s (- 18m 37s) (20000 26%) 1.2747\n",
      "8m 27s (- 16m 54s) (25000 33%) 1.2529\n",
      "10m 7s (- 15m 11s) (30000 40%) 1.2316\n",
      "11m 49s (- 13m 30s) (35000 46%) 1.2196\n",
      "13m 30s (- 11m 49s) (40000 53%) 1.2261\n",
      "15m 12s (- 10m 8s) (45000 60%) 1.2207\n",
      "16m 53s (- 8m 26s) (50000 66%) 1.2111\n",
      "18m 33s (- 6m 44s) (55000 73%) 1.1981\n",
      "20m 14s (- 5m 3s) (60000 80%) 1.2105\n",
      "21m 55s (- 3m 22s) (65000 86%) 1.1995\n",
      "23m 36s (- 1m 41s) (70000 93%) 1.1951\n",
      "25m 18s (- 0m 0s) (75000 100%) 1.1924\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> „ÇÑ„Å£„Å±„Çä „ÄÅ „Ç∏„É£„Ç∫ „Å£„Å¶ Ê•Ω„Åó„ÅÑ \n",
      "= 6\n",
      "original emoji =  ['üòä']\n",
      "< 6 <EOS>\n",
      "output emoji <  ['üòä']\n",
      "\n",
      "> „ÅÑ„Åæ ÈáéËèú „Å´ „Å™„Å£ „Å¶„Çã „Çà  \n",
      "= 3\n",
      "original emoji =  ['üòÇ']\n",
      "< 4 <EOS>\n",
      "output emoji <  ['üíï']\n",
      "\n",
      "> ÂâçÊó• „Å®„Åã Á©∫Ê∞ó ÊÇ™ „Åô„Åé „Å¶ „Å©„ÅÜ „Å™„Çã „Åã „Å® ÊÄù„Å£ „Åü „Åë„Å© ÈáëË≥û „Å®„Çå „Å¶ „Çà„Åã„Å£ „Åü \n",
      "= 6\n",
      "original emoji =  ['üòä']\n",
      "< 3 <EOS>\n",
      "output emoji <  ['üòÇ']\n",
      "\n",
      "> „Åó„Çá ÔΩû „ÇÜ ÔΩû ‰∫ã „Åß„Åô „Å™ \n",
      "= 15\n",
      "original emoji =  ['üòâ']\n",
      "< 18 <EOS>\n",
      "output emoji <  ['üí¶']\n",
      "\n",
      ">  ÂΩºÊ∞è ÂΩºÂ•≥ „ÅÑ „Åù„ÅÜ „Åä „Çã„Çì\n",
      "= 2\n",
      "original emoji =  ['üòç']\n",
      "< 2 <EOS>\n",
      "output emoji <  ['üòç']\n",
      "\n",
      "> ÊôÆÊÆµ „Åã„Çâ „Åó „Å™„ÅÑ „Å® „Å™„Éº \n",
      "= 10\n",
      "original emoji =  ['üòÖ']\n",
      "< 3 <EOS>\n",
      "output emoji <  ['üòÇ']\n",
      "\n",
      "> Á¥†Êïµ „Å™ ‰∏Ä Êó• „Å´ „Å™„Çä „Åæ„Åô „Çà„ÅÜ „Å´ „ÄÅ ÂøÉ„Åã„Çâ È°ò„Å£ „Å¶ „ÅÑ „Åæ„Åô \n",
      "= 19\n",
      "original emoji =  ['üòÜ']\n",
      "< 8 <EOS>\n",
      "output emoji <  ['‚ú®']\n",
      "\n",
      "> „Éê„Çπ„Ç± „ÅÆ „Éû„Éç„Éº„Ç∏„É£„Éº „Åó „Å¶ „ÅØ„Å£ „Å¶ „ÇÅ„Å£„Å°„ÇÉ „Åã„Å£„Åì„ÅÑ„ÅÑ „Åß„Åô \n",
      "= 8\n",
      "original emoji =  ['‚ú®']\n",
      "< 3 <EOS>\n",
      "output emoji <  ['üòÇ']\n",
      "\n",
      "> Ë¶ã „Çå„Çã „ÅÆ Ê•Ω„Åó„Åø „Å† „Å™ÔΩû \n",
      "= 6\n",
      "original emoji =  ['üòä']\n",
      "< 8 <EOS>\n",
      "output emoji <  ['‚ú®']\n",
      "\n",
      "> Áü•„ÇäÂêà„Å£ „Å¶ ÊôÇÈñì „ÅÆ ‰∫∫ „Å® È¨º ‰ª≤ËâØ„Åè „Å™„Çã „Å£„Å¶ „Å™„Å´ „Çà \n",
      "= 3\n",
      "original emoji =  ['üòÇ']\n",
      "< 3 <EOS>\n",
      "output emoji <  ['üòÇ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"‰ª≤ËâØ„Åè „Åó „Å¶\")\n",
    "plt.matshow(attentions.numpy())\n",
    "plt.savefig('frendme.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig('frendme.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    print('output emoji = ', emojiFromIndex(int(output_words[0])))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = „Å™„Åä „ÇØ„É≥ „ÅØ Ê∞óÂúß „ÅÆ Â§âÂåñ „Å´ „ÇÇ Âº±„ÅÑ „Åã„Çâ „ÄÅ „ÅÑ„Çç„ÅÑ„Çç ÂøÉÈÖç „Åß „ÅÇ„Çä „ÇÑ„Åô „ÄÅ „ÄÅ „ÄÅ\n",
      "output = 8 <EOS>\n",
      "output emoji =  ['‚ú®']\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"„Å™„Åä „ÇØ„É≥ „ÅØ Ê∞óÂúß „ÅÆ Â§âÂåñ „Å´ „ÇÇ Âº±„ÅÑ „Åã„Çâ „ÄÅ „ÅÑ„Çç„ÅÑ„Çç ÂøÉÈÖç „Åß „ÅÇ„Çä „ÇÑ„Åô „ÄÅ „ÄÅ „ÄÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.33333333 0.         0.09174312 0.23809524 0.         0.2406015\n",
      " 0.         0.27078385 0.33333333 0.25       0.425      0.23529412\n",
      " 0.2        0.         0.         0.5        0.54166667 0.36363636\n",
      " 0.         0.        ]\n",
      "report              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.33      0.08      0.13        24\n",
      "          2       0.00      0.00      0.00        22\n",
      "          3       0.09      0.44      0.15        45\n",
      "          4       0.24      0.19      0.21        77\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.24      0.26      0.25       122\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.27      0.58      0.37       196\n",
      "          9       0.33      0.27      0.30        15\n",
      "         10       0.25      0.02      0.04        84\n",
      "         11       0.42      0.37      0.40        46\n",
      "         12       0.24      0.14      0.18        28\n",
      "         13       0.20      0.07      0.11        54\n",
      "         14       0.00      0.00      0.00        14\n",
      "         15       0.00      0.00      0.00        28\n",
      "         16       0.50      0.50      0.50         6\n",
      "         17       0.54      0.16      0.25        81\n",
      "         18       0.36      0.19      0.25       124\n",
      "         19       0.00      0.00      0.00        55\n",
      "         20       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.26      0.24      0.21      1045\n",
      "\n",
      "accuracy score 0.2430622009569378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluateTestdata(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
